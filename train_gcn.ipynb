{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphNorm\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create saving directories if they do not exist\n",
    "if not os.path.exists(\"./training-runs\"):\n",
    "    os.mkdir(\"./training-runs\")\n",
    "\n",
    "if not os.path.exists(os.path.join(\"./training-runs\", \"gcn\")):\n",
    "    os.mkdir(os.path.join(\"./training-runs\", \"gcn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment directory for this run\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d-%H_%M_%S')\n",
    "SAVE_PATH = os.path.join(\"./training-runs\", \"gcn\", date)\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = Planetoid(root=\"./\", name=\"Cora\", split=\"public\")\n",
    "cora_dataset = cora[0]\n",
    "cora_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print size of train, validation, and test set\n",
    "print(cora_dataset.train_mask.sum())\n",
    "print(cora_dataset.val_mask.sum())\n",
    "print(cora_dataset.test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_epochs\": 100,\n",
    "    \"hidden_size\": 40,\n",
    "    \"experiment description\": \"Two-hop GCN Network, hidden size 40, SGD optimizer + momentum=0.9, learning rate 1e-1. Dropout with probability 0.5 before GCN layers, Graph Norm after GCN layer.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_size, num_classes, training=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_features, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.norm1 = GraphNorm(hidden_size)\n",
    "        self.norm2 = GraphNorm(hidden_size)\n",
    "\n",
    "        self.lin1 = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.drop1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.drop2(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(cora_dataset.num_node_features, hidden_size=args[\"hidden_size\"], num_classes=cora.num_classes).to(device)\n",
    "\n",
    "cora_dataset = cora_dataset.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=args[\"learning_rate\"], weight_decay=5e-4)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args[\"learning_rate\"], momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(train_losses, val_losses):\n",
    "    assert len(train_losses) == len(val_losses), \"Inconsistent plotting sizes.\"\n",
    "    \n",
    "    time = list(range(args[\"num_epochs\"]))\n",
    "    visual_df = pd.DataFrame({\n",
    "        \"Train Loss\": train_losses,\n",
    "        \"Validation Loss\": val_losses,\n",
    "        \"Epoch\": time\n",
    "    })\n",
    "\n",
    "    sns.lineplot(x='Epoch', y='Loss Value', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Loss Value\", var_name=\"Dataset Split\"))\n",
    "    plt.title(\"Loss Curves\")\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"loss_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_curves(train_acc, val_acc):\n",
    "    assert len(train_acc) == len(val_acc), \"Inconsistent plotting sizes.\"\n",
    "    \n",
    "    time = list(range(args[\"num_epochs\"]))\n",
    "    visual_df = pd.DataFrame({\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Validation Accuracy\": val_acc,\n",
    "        \"Epoch\": time\n",
    "    })\n",
    "\n",
    "    sns.lineplot(x='Epoch', y='Accuracy', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Accuracy\", var_name=\"Dataset Split\"))\n",
    "    plt.title(\"Accuracy Curves\")\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"accuracy_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training and Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, cora_dataset):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(args[\"num_epochs\"]):\n",
    "        if epoch % 20 == 0:\n",
    "            print(\"Epoch {} starting...\".format(epoch))\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(cora_dataset)  # Pass entire graph through model at once - batch gradient descent\n",
    "        loss = F.nll_loss(out[cora_dataset.train_mask], cora_dataset.y[cora_dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = (pred[cora_dataset.train_mask] == cora_dataset.y[cora_dataset.train_mask]).sum()\n",
    "        train_acc = int(correct) / int(cora_dataset.train_mask.sum())\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validate once per epoch\n",
    "        val_loss, val_acc = validation(model, cora_dataset)\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Assert that sizes are all the same\n",
    "    assert len(train_losses) == len(val_losses) == len(train_accuracies) == len(val_accuracies), \"Metric list sizes are inconsistent.\"\n",
    "    plot_loss_curves(train_losses, val_losses)\n",
    "    plot_accuracy_curves(train_accuracies, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, cora_dataset):\n",
    "    model.eval()\n",
    "    out = model(cora_dataset)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    val_loss = F.nll_loss(out[cora_dataset.val_mask], cora_dataset.y[cora_dataset.val_mask])\n",
    "    correct = (pred[cora_dataset.val_mask] == cora_dataset.y[cora_dataset.val_mask]).sum()\n",
    "    val_acc = int(correct) / int(cora_dataset.val_mask.sum())\n",
    "    \n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, cora_dataset):\n",
    "    model.eval()\n",
    "    pred = model(cora_dataset).argmax(dim=1)\n",
    "    correct = (pred[cora_dataset.test_mask] == cora_dataset.y[cora_dataset.test_mask]).sum()\n",
    "    accuracy = int(correct) / int(cora_dataset.test_mask.sum())\n",
    "    print(f'Test Set Accuracy: {accuracy:.4f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, cora_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = test(model, cora_dataset)\n",
    "\n",
    "# Save test accuracy so that we log it somewhere. Train and val accuracy are kept in the accuracy curves\n",
    "args[\"test accuracy\"] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training configuration and experiment description\n",
    "with open(os.path.join(SAVE_PATH, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(args, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print model definition\n",
    "open(os.path.join(SAVE_PATH, \"model_definition.txt\"), 'a').close()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c3ec5cb0d81e7b9f9908a53ca28aa4318265e5d52f388cac911a9765dd2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
