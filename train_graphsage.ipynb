{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GraphNorm\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import NeighborSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create saving directories if they do not exist\n",
    "if not os.path.exists(\"./training-runs\"):\n",
    "    os.mkdir(\"./training-runs\")\n",
    "\n",
    "if not os.path.exists(os.path.join(\"./training-runs\", \"graphsage\")):\n",
    "    os.mkdir(os.path.join(\"./training-runs\", \"graphsage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment directory for this run\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d-%H_%M_%S')\n",
    "SAVE_PATH = os.path.join(\"./training-runs\", \"graphsage\", date)\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = Planetoid(root=\"./\", name=\"Cora\", split=\"public\")\n",
    "cora_dataset = cora[0]\n",
    "cora_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print size of train, validation, and test set\n",
    "print(cora_dataset.train_mask.sum())\n",
    "print(cora_dataset.val_mask.sum())\n",
    "print(cora_dataset.test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 100,\n",
    "    \"hidden_size\": 40,\n",
    "    \"neighbor_sample\": 20,\n",
    "    \"experiment description\": \"Two-hop GraphSAGE Network, useing neighbor sampler module in Pytorch Geometric to do neighbor sampling as part of the GraphSAGE algorithm. Adam optimizer, learning rate 1e-3.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GraphSAGE, we will use the NeighborSampler module in Pytorch Geometric to sample a fixed-size neighborhood of each node. This will allow us to operate on large graphs that do not fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to get node indices that are part of training set\n",
    "train_node_idxs = torch.where(cora_dataset.train_mask == True)[0]\n",
    "train_loader = NeighborSampler(cora_dataset.edge_index, sizes=[args[\"neighbor_sample\"], args[\"neighbor_sample\"]], node_idx=train_node_idxs, batch_size=1024, shuffle=True)\n",
    "\n",
    "# Subgraph loader will be for evaluation\n",
    "subgraph_loader = NeighborSampler(cora_dataset.edge_index, node_idx=None, sizes=[-1], batch_size=4096, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = 2\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(input_features, hidden_size, normalize=False, root_weight=True, bias=True))\n",
    "        self.convs.append(SAGEConv(hidden_size, hidden_size, normalize=False, root_weight=True, bias=True))\n",
    "\n",
    "        self.norm1 = GraphNorm(hidden_size)\n",
    "        self.norm2 = GraphNorm(hidden_size)\n",
    "\n",
    "        self.lin1 = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        # Forward function code based on tutorial from PyTorch Geometric for handling neighbor sampling dataloader\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "\n",
    "            # x = self.norm1(x) if i == 0 else self.norm2(x)\n",
    "            x = F.relu(x)\n",
    "            # x = F.dropout(x, p=0.5, training=True)  # Validation/Test will not call forward function\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def inference(self, x_all):\n",
    "        # Inference code for to compute node representations for all nodes at test time taken from \n",
    "        # PyTorch Geometric sample code: \n",
    "        # https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py\n",
    "        \n",
    "        total_edges = 0\n",
    "        for i in range(self.num_layers):\n",
    "            xs = []\n",
    "            for batch_size, n_id, adj in subgraph_loader:\n",
    "                edge_index, _, size = adj.to(device)\n",
    "                total_edges += edge_index.size(1)\n",
    "                x = x_all[n_id].to(device)\n",
    "                x_target = x[:size[1]]\n",
    "                x = self.convs[i]((x, x_target), edge_index)\n",
    "                # x = self.norm1(x) if i == 0 else self.norm2(x)\n",
    "                x = F.relu(x)\n",
    "                xs.append(x.cpu())\n",
    "\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "        \n",
    "        x = self.lin1(x_all)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(cora_dataset.num_node_features, hidden_size=args[\"hidden_size\"], num_classes=cora.num_classes).to(device)\n",
    "\n",
    "cora_dataset = cora_dataset.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args[\"learning_rate\"], weight_decay=5e-4)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=args[\"learning_rate\"], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(train_losses, val_losses):\n",
    "    assert len(train_losses) == len(val_losses), \"Inconsistent plotting sizes.\"\n",
    "    \n",
    "    time = list(range(args[\"num_epochs\"]))\n",
    "    visual_df = pd.DataFrame({\n",
    "        \"Train Loss\": train_losses,\n",
    "        \"Validation Loss\": val_losses,\n",
    "        \"Epoch\": time\n",
    "    })\n",
    "\n",
    "    sns.lineplot(x='Epoch', y='Loss Value', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Loss Value\", var_name=\"Dataset Split\"))\n",
    "    plt.title(\"Loss Curves\")\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"loss_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_curves(train_acc, val_acc):\n",
    "    assert len(train_acc) == len(val_acc), \"Inconsistent plotting sizes.\"\n",
    "    \n",
    "    time = list(range(args[\"num_epochs\"]))\n",
    "    visual_df = pd.DataFrame({\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Validation Accuracy\": val_acc,\n",
    "        \"Epoch\": time\n",
    "    })\n",
    "\n",
    "    sns.lineplot(x='Epoch', y='Accuracy', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Accuracy\", var_name=\"Dataset Split\"))\n",
    "    plt.title(\"Accuracy Curves\")\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"accuracy_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training and Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, cora_dataset):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    pbar = tqdm(total=args[\"num_epochs\"])\n",
    "    pbar.set_description(f'Epoch')\n",
    "\n",
    "    for epoch in range(args[\"num_epochs\"]):        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss = 0.\n",
    "        total_correct = 0.\n",
    "        \n",
    "        for batch_size, n_id, adjs in train_loader:\n",
    "            adjs = [adj.to(device) for adj in adjs]\n",
    "\n",
    "            out = model(cora_dataset.x[n_id], adjs)  # Pass sampled neighbors to model\n",
    "            loss = F.nll_loss(out, cora_dataset.y[n_id[:batch_size]])\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred = out.argmax(dim=1)\n",
    "            total_correct += (pred == cora_dataset.y[n_id[:batch_size]]).sum()\n",
    "        \n",
    "        train_acc = int(total_correct) / int(cora_dataset.train_mask.sum())\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validate once per epoch\n",
    "        val_loss, val_acc = validation(model, cora_dataset)\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        pbar.update(epoch)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Assert that sizes are all the same\n",
    "    assert len(train_losses) == len(val_losses) == len(train_accuracies) == len(val_accuracies), \"Metric list sizes are inconsistent.\"\n",
    "    plot_loss_curves(train_losses, val_losses)\n",
    "    plot_accuracy_curves(train_accuracies, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, cora_dataset):\n",
    "    model.eval()\n",
    "    out = model.inference(cora_dataset.x)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    val_loss = F.nll_loss(out[cora_dataset.val_mask], cora_dataset.y[cora_dataset.val_mask])\n",
    "    correct = (pred[cora_dataset.val_mask] == cora_dataset.y[cora_dataset.val_mask]).sum()\n",
    "    val_acc = int(correct) / int(cora_dataset.val_mask.sum())\n",
    "    \n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, cora_dataset):\n",
    "    model.eval()\n",
    "    pred = model.inference(cora_dataset.x).argmax(dim=1)\n",
    "    correct = (pred[cora_dataset.test_mask] == cora_dataset.y[cora_dataset.test_mask]).sum()\n",
    "    accuracy = int(correct) / int(cora_dataset.test_mask.sum())\n",
    "    print(f'Test Set Accuracy: {accuracy:.4f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, cora_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = test(model, cora_dataset)\n",
    "\n",
    "# Save test accuracy so that we log it somewhere. Train and val accuracy are kept in the accuracy curves\n",
    "args[\"test accuracy\"] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training configuration and experiment description\n",
    "with open(os.path.join(SAVE_PATH, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(args, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print model definition\n",
    "open(os.path.join(SAVE_PATH, \"model_definition.txt\"), 'a').close()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c3ec5cb0d81e7b9f9908a53ca28aa4318265e5d52f388cac911a9765dd2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
