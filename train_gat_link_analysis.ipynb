{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create saving directories if they do not exist\n",
    "if not os.path.exists(\"./training-runs\"):\n",
    "    os.mkdir(\"./training-runs\")\n",
    "\n",
    "if not os.path.exists(os.path.join(\"./training-runs\", \"gat\")):\n",
    "    os.mkdir(os.path.join(\"./training-runs\", \"gat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment directory for this run\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d-%H_%M_%S')\n",
    "SAVE_PATH = os.path.join(\"./training-runs\", \"gat\", date)\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora = Planetoid(root=\"./\", name=\"Cora\", split=\"public\")\n",
    "cora_dataset = cora[0]\n",
    "cora_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(140)\n",
      "tensor(500)\n",
      "tensor(1000)\n"
     ]
    }
   ],
   "source": [
    "# Print size of train, validation, and test set\n",
    "print(cora_dataset.train_mask.sum())\n",
    "print(cora_dataset.val_mask.sum())\n",
    "print(cora_dataset.test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_epochs\": 100,\n",
    "    \"hidden_size\": 64,\n",
    "    \"experiment description\": \"Two-hop GAT Network, Adam optimizer.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_size, num_classes, training=True):\n",
    "        super().__init__()\n",
    "        # Model definition follows GAT architecture described in \"Graph Attention Networks\", Velickovic et al.:\n",
    "        # https://arxiv.org/pdf/1710.10903.pdf\n",
    "\n",
    "        self.conv1 = GATConv(in_channels=input_features, out_channels=hidden_size // 8, heads=8)\n",
    "        self.conv2 = GATConv(hidden_size, num_classes, heads=1)\n",
    "\n",
    "        self.act1 = nn.ELU()\n",
    "        self.drop1 = nn.Dropout(p=0.6)\n",
    "        self.drop2 = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.drop1(x)\n",
    "        x, (edge_idx1, alphas1) = self.conv1(x, edge_index, return_attention_weights=True)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.drop2(x)\n",
    "        x, (edge_idx2, alphas2) = self.conv2(x, edge_index, return_attention_weights=True)\n",
    "        return F.softmax(x, dim=1), (edge_idx1, alphas1, edge_idx2, alphas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT(cora_dataset.num_node_features, hidden_size=args[\"hidden_size\"], num_classes=cora.num_classes).to(device)\n",
    "\n",
    "cora_dataset = cora_dataset.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args[\"learning_rate\"], weight_decay=5e-4)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=args[\"learning_rate\"], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(train_losses, val_losses):\n",
    "    assert len(train_losses) == len(val_losses), \"Inconsistent plotting sizes.\"\n",
    "    \n",
    "    time = list(range(args[\"num_epochs\"]))\n",
    "    visual_df = pd.DataFrame({\n",
    "        \"Train Loss\": train_losses,\n",
    "        \"Validation Loss\": val_losses,\n",
    "        \"Epoch\": time\n",
    "    })\n",
    "\n",
    "    sns.lineplot(x='Epoch', y='Loss Value', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Loss Value\", var_name=\"Dataset Split\"))\n",
    "    plt.title(\"Loss Curves\")\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"loss_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_curves(train_acc, val_acc):\n",
    "    assert len(train_acc) == len(val_acc), \"Inconsistent plotting sizes.\"\n",
    "    \n",
    "    time = list(range(args[\"num_epochs\"]))\n",
    "    visual_df = pd.DataFrame({\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Validation Accuracy\": val_acc,\n",
    "        \"Epoch\": time\n",
    "    })\n",
    "\n",
    "    sns.lineplot(x='Epoch', y='Accuracy', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Accuracy\", var_name=\"Dataset Split\"))\n",
    "    plt.title(\"Accuracy Curves\")\n",
    "    plt.savefig(os.path.join(SAVE_PATH, \"accuracy_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training and Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, cora_dataset):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    pbar = tqdm(total=args[\"num_epochs\"])\n",
    "    pbar.set_description(f'Epoch')\n",
    "\n",
    "    for epoch in range(args[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out, _ = model(cora_dataset)  # Pass entire graph through model\n",
    "        loss = F.nll_loss(out[cora_dataset.train_mask], cora_dataset.y[cora_dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = (pred[cora_dataset.train_mask] == cora_dataset.y[cora_dataset.train_mask]).sum()\n",
    "        train_acc = int(correct) / int(cora_dataset.train_mask.sum())\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validate once per epoch\n",
    "        val_loss, val_acc = validation(model, cora_dataset)\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        pbar.update(epoch)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Assert that sizes are all the same\n",
    "    assert len(train_losses) == len(val_losses) == len(train_accuracies) == len(val_accuracies), \"Metric list sizes are inconsistent.\"\n",
    "    plot_loss_curves(train_losses, val_losses)\n",
    "    plot_accuracy_curves(train_accuracies, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, cora_dataset):\n",
    "    model.eval()\n",
    "    out, _ = model(cora_dataset)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    val_loss = F.nll_loss(out[cora_dataset.val_mask], cora_dataset.y[cora_dataset.val_mask])\n",
    "    correct = (pred[cora_dataset.val_mask] == cora_dataset.y[cora_dataset.val_mask]).sum()\n",
    "    val_acc = int(correct) / int(cora_dataset.val_mask.sum())\n",
    "    \n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, cora_dataset):\n",
    "    model.eval()\n",
    "    out, edge_attn_info = model(cora_dataset)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[cora_dataset.test_mask] == cora_dataset.y[cora_dataset.test_mask]).sum()\n",
    "    accuracy = int(correct) / int(cora_dataset.test_mask.sum())\n",
    "    print(f'Test Set Accuracy: {accuracy:.4f}')\n",
    "    return accuracy, edge_attn_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: : 210it [00:02, 166.61it/s]                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: : 820it [00:03, 376.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: : 1830it [00:05, 566.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: : 3240it [00:07, 830.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: : 4950it [00:09, 527.58it/s] \n"
     ]
    }
   ],
   "source": [
    "train(model, cora_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "test_acc, edge_attn_info = test(model, cora_dataset)\n",
    "\n",
    "# Save test accuracy so that we log it somewhere. Train and val accuracy are kept in the accuracy curves\n",
    "args[\"test accuracy\"] = test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Graph Attention Networks, we can extract attention scores computed between nodes in the graph. These scores are an interpretable similarity measure computed by the attention mechanism defined in the \"Graph Attention Networks\" publication.\n",
    "\n",
    "These attention scores can serve as edge weights if we so desire, or we could train auxillary classifiers to classify the scores into link predictions. Any future analysis of link-level tasks in the graph-structured data could be done through these attention scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13264]) torch.Size([13264, 8]) torch.Size([2, 13264]) torch.Size([13264, 1])\n"
     ]
    }
   ],
   "source": [
    "(edge_idx1, alphas1, edge_idx2, alphas2) = edge_attn_info\n",
    "print(edge_idx1.shape, alphas1.shape, edge_idx2.shape, alphas2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT Layer 1 Attention Scores:\n",
      "Average GAT attention score from node 0 to node 633 is 0.2268\n",
      "Average GAT attention score from node 0 to node 1862 is 0.1792\n",
      "Average GAT attention score from node 0 to node 2582 is 0.2378\n",
      "Average GAT attention score from node 1 to node 2 is 0.2019\n",
      "Average GAT attention score from node 1 to node 652 is 0.3429\n",
      "Average GAT attention score from node 1 to node 654 is 0.4538\n",
      "Average GAT attention score from node 2 to node 1 is 0.2340\n",
      "Average GAT attention score from node 2 to node 332 is 0.1857\n",
      "Average GAT attention score from node 2 to node 1454 is 0.4882\n",
      "Average GAT attention score from node 2 to node 1666 is 0.1591\n",
      "Average GAT attention score from node 2 to node 1986 is 0.0195\n",
      "Average GAT attention score from node 3 to node 2544 is 0.5116\n",
      "Average GAT attention score from node 4 to node 1016 is 0.1894\n",
      "Average GAT attention score from node 4 to node 1256 is 0.1314\n",
      "Average GAT attention score from node 4 to node 1761 is 0.1523\n"
     ]
    }
   ],
   "source": [
    "print(\"GAT Layer 1 Attention Scores:\")\n",
    "for i in range(15):\n",
    "    print(\"Average GAT attention score from node {} to node {} is {:.4f}\".format(edge_idx1[0,i], edge_idx1[1,i], alphas1[i,:].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT Layer 2 Attention Scores:\n",
      "Average GAT attention score from node 0 to node 633 is 0.2662\n",
      "Average GAT attention score from node 0 to node 1862 is 0.2137\n",
      "Average GAT attention score from node 0 to node 2582 is 0.2581\n",
      "Average GAT attention score from node 1 to node 2 is 0.1513\n",
      "Average GAT attention score from node 1 to node 652 is 0.3237\n",
      "Average GAT attention score from node 1 to node 654 is 0.5085\n",
      "Average GAT attention score from node 2 to node 1 is 0.2778\n",
      "Average GAT attention score from node 2 to node 332 is 0.1754\n",
      "Average GAT attention score from node 2 to node 1454 is 0.5079\n",
      "Average GAT attention score from node 2 to node 1666 is 0.1422\n",
      "Average GAT attention score from node 2 to node 1986 is 0.0142\n",
      "Average GAT attention score from node 3 to node 2544 is 0.4969\n",
      "Average GAT attention score from node 4 to node 1016 is 0.1699\n",
      "Average GAT attention score from node 4 to node 1256 is 0.1081\n",
      "Average GAT attention score from node 4 to node 1761 is 0.1235\n"
     ]
    }
   ],
   "source": [
    "print(\"GAT Layer 2 Attention Scores:\")\n",
    "for i in range(15):\n",
    "    print(\"Average GAT attention score from node {} to node {} is {:.4f}\".format(edge_idx2[0,i], edge_idx2[1,i], alphas2[i,:].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13264, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small Exercise: Find largest attention score, see if two nodes have the same class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13264])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas1_average = alphas1.mean(dim=1)\n",
    "alphas1_average.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13061)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(alphas1_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average GAT attention score from node 447 to node 2638 is 0.5437\n"
     ]
    }
   ],
   "source": [
    "print(\"Average GAT attention score from node {} to node {} is {:.4f}\".format(edge_idx1[0,1840], edge_idx1[1,1840], alphas1[1840,:].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "print(cora_dataset.y[447])\n",
    "print(cora_dataset.y[2638])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high similarity score indeed indicated that the two nodes had the same class label. This means that when the GAT layer was computing attention between the node embeddings of nodes 447 and 2638, which were one-hot encoded words from scientific papers, the attention mechanism computed higher similarity between the word dictionary embeddings because the two papers had the same subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (conv1): GATConv(1433, 8, heads=8)\n",
      "  (conv2): GATConv(64, 7, heads=1)\n",
      "  (act1): ELU(alpha=1.0)\n",
      "  (drop1): Dropout(p=0.6, inplace=False)\n",
      "  (drop2): Dropout(p=0.6, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Save training configuration and experiment description\n",
    "with open(os.path.join(SAVE_PATH, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(args, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print model definition\n",
    "open(os.path.join(SAVE_PATH, \"model_definition.txt\"), 'a').close()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance: run6, 80.7% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c3ec5cb0d81e7b9f9908a53ca28aa4318265e5d52f388cac911a9765dd2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
